{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "0cr5SzZg7-3g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "jtFkQ5Mm8DOg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, name):\n",
        "  if not os.path.exists(name):\n",
        "    filedir, filename = os.path.split(name)\n",
        "    os.makedirs(filedir, exist_ok = True)\n",
        "    response = requests.get(url, stream=True)\n",
        "    ckpt_file = name \n",
        "    with open(ckpt_file, 'wb') as file:\n",
        "      for data in response.iter_content(chunk_size=1024):\n",
        "        file.write(data)"
      ],
      "metadata": {
        "id": "v3N_nXpP8FXn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_file('https://github.com/ftokarev/tf-vgg-weights/raw/master/vgg19_weights_normalized.h5',\n",
        "                                'vgg_weights/vgg19_weights_normalized.h')"
      ],
      "metadata": {
        "id": "15yGQcNa8MeX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = h5py.File('/content/vgg_weights/vgg19_weights_normalized.h', mode='r')"
      ],
      "metadata": {
        "id": "T34D6z2r8Nie"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 정규화\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "\n",
        "class Normalization(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalization, self).__init__()\n",
        "        self.mean = mean.clone().view(-1, 1, 1)\n",
        "        self.std = std.clone().view(-1, 1, 1)\n",
        "\n",
        "    def forward(self, img):\n",
        "        return (img - self.mean) / self.std"
      ],
      "metadata": {
        "id": "U6CJyH8K9hCo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvRelu(torch.nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size=3,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 dilation=1,\n",
        "                 groups=1,\n",
        "                 bias: bool = True,\n",
        "                 padding_mode: str = 'zeros'\n",
        "                 ):\n",
        "        super(ConvRelu, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation,\n",
        "                              groups=groups, bias=bias, padding_mode=padding_mode)\n",
        "        self.relu = nn.ReLU()"
      ],
      "metadata": {
        "id": "bN_qQ5nD8XEi"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(torch.nn.Sequential):\n",
        "  def __init__(self, param_file):\n",
        "    super(VGG, self).__init__()\n",
        "    self.f = h5py.File(param_file, mode='r')\n",
        "    self.normalization = Normalization(mean, std)\n",
        "\n",
        "    self.conv1_1 = ConvRelu(3, 64)\n",
        "    self.conv1_2 = ConvRelu(64, 64)\n",
        "    self.pool1 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "    self.conv2_1 = ConvRelu(64, 128)\n",
        "    self.conv2_2 = ConvRelu(128, 128)\n",
        "    self.pool2 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "    self.conv3_1 = ConvRelu(128, 256)\n",
        "    self.conv3_2 = ConvRelu(256, 256)\n",
        "    self.conv3_3 = ConvRelu(256, 256)\n",
        "    self.conv3_4 = ConvRelu(256, 256)\n",
        "    self.pool3 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "    self.conv4_1 = ConvRelu(256, 512)\n",
        "    self.conv4_2 = ConvRelu(512, 512)\n",
        "    self.conv4_3 = ConvRelu(512, 512)\n",
        "    self.conv4_4 = ConvRelu(512, 512)\n",
        "    self.pool4 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "    self.conv5_1 = ConvRelu(512, 512)\n",
        "    self.conv5_2 = ConvRelu(512, 512)\n",
        "    self.conv5_3 = ConvRelu(512, 512)\n",
        "    self.conv5_4 = ConvRelu(512, 512)\n",
        "    self.pool5 = nn.MaxPool2d(2, stride=2)\n",
        "    \n",
        "    #parameter가 training 되지 않게.\n",
        "    for p in self.parameters():\n",
        "            p.requires_grad_(False)\n",
        "\n",
        "    self.load_params()\n",
        "\n",
        "    \n",
        "  def load_params(self):\n",
        "        trained = [np.array(layer[1], 'float32') for layer in list(self.f.items())]\n",
        "        weight_value_tuples = []\n",
        "        for p, tp in zip(self.parameters(), trained):\n",
        "            if len(tp.shape) == 4:\n",
        "                tp = np.transpose(tp, (3, 2, 0, 1))\n",
        "            weight_value_tuples.append((p, tp))\n",
        "\n",
        "        paramvalues = zip(*(weight_value_tuples))\n",
        "\n",
        "        #parameter 위치에 대응하는 pretrained된 값 입력 \n",
        "        for p, v in zip(*paramvalues):\n",
        "          p.data.copy_(torch.from_numpy(v).data)\n",
        "\n",
        "        \n",
        "  def extra_features(self, x):\n",
        "    features ={}\n",
        "    x = self.normalization(x)\n",
        "    x = self.conv1_1(x)\n",
        "    features['conv1_1'] = x\n",
        "    x = self.conv1_2(x)\n",
        "    features['conv1_2'] = x\n",
        "    x = self.pool1(x)\n",
        "    features['conv1_2_pool'] = x\n",
        "\n",
        "    x = self.conv2_1(x)\n",
        "    features['conv2_1'] = x\n",
        "    x = self.conv2_2(x)\n",
        "    features['conv2_2'] = x\n",
        "    x = self.pool2(x)\n",
        "    features['conv2_2_pool'] = x\n",
        "    \n",
        "    x = self.conv3_1(x)\n",
        "    features['conv3_1'] = x\n",
        "    x = self.conv3_2(x)\n",
        "    features['conv3_2'] = x\n",
        "    x = self.conv3_3(x)\n",
        "    features['conv3_3'] = x\n",
        "    x = self.conv3_4(x)\n",
        "    features['conv3_4'] = x\n",
        "    x = self.pool3(x)\n",
        "    features['conv3_4_pool'] = x\n",
        "\n",
        "    x = self.conv4_1(x)\n",
        "    features['conv4_1'] = x\n",
        "    x = self.conv4_2(x)\n",
        "    features['conv4_2'] = x\n",
        "    x = self.conv4_3(x)\n",
        "    features['conv4_3'] = x\n",
        "    x = self.conv4_4(x)\n",
        "    features['conv4_4'] = x\n",
        "    x = self.pool4(x)\n",
        "    features['conv4_4_pool'] = x\n",
        "\n",
        "    x = self.conv5_1(x)\n",
        "    features['conv5_1'] = x\n",
        "    x = self.conv5_2(x)\n",
        "    features['conv5_2'] = x\n",
        "    x = self.conv5_3(x)\n",
        "    features['conv5_3'] = x\n",
        "    x = self.conv5_4(x)\n",
        "    features['conv5_4'] = x\n",
        "    x = self.pool5(x)\n",
        "    features['conv5_4_pool'] = x\n",
        "\n",
        "    return features\n",
        "    "
      ],
      "metadata": {
        "id": "X8xxcWKR8ble"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}